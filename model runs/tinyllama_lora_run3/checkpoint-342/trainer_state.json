{
  "best_global_step": 342,
  "best_metric": 1.3889195919036865,
  "best_model_checkpoint": "./tinyllama_lora_run3/checkpoint-342",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 342,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05847953216374269,
      "grad_norm": 0.3508497178554535,
      "learning_rate": 4.5e-05,
      "loss": 2.2995380401611327,
      "step": 10
    },
    {
      "epoch": 0.11695906432748537,
      "grad_norm": 0.33350569009780884,
      "learning_rate": 4.8644578313253016e-05,
      "loss": 2.194833755493164,
      "step": 20
    },
    {
      "epoch": 0.17543859649122806,
      "grad_norm": 0.2915598154067993,
      "learning_rate": 4.713855421686747e-05,
      "loss": 2.057417106628418,
      "step": 30
    },
    {
      "epoch": 0.23391812865497075,
      "grad_norm": 0.4301954507827759,
      "learning_rate": 4.563253012048193e-05,
      "loss": 1.8892330169677733,
      "step": 40
    },
    {
      "epoch": 0.29239766081871343,
      "grad_norm": 0.4619322419166565,
      "learning_rate": 4.412650602409639e-05,
      "loss": 1.696027946472168,
      "step": 50
    },
    {
      "epoch": 0.3508771929824561,
      "grad_norm": 0.2877512276172638,
      "learning_rate": 4.262048192771085e-05,
      "loss": 1.5059283256530762,
      "step": 60
    },
    {
      "epoch": 0.4093567251461988,
      "grad_norm": 0.23320454359054565,
      "learning_rate": 4.11144578313253e-05,
      "loss": 1.447458267211914,
      "step": 70
    },
    {
      "epoch": 0.4678362573099415,
      "grad_norm": 0.1853293478488922,
      "learning_rate": 3.960843373493976e-05,
      "loss": 1.4433175086975099,
      "step": 80
    },
    {
      "epoch": 0.5263157894736842,
      "grad_norm": 0.1936897337436676,
      "learning_rate": 3.810240963855422e-05,
      "loss": 1.4295099258422852,
      "step": 90
    },
    {
      "epoch": 0.5847953216374269,
      "grad_norm": 0.1790643334388733,
      "learning_rate": 3.659638554216868e-05,
      "loss": 1.4377429962158204,
      "step": 100
    },
    {
      "epoch": 0.6432748538011696,
      "grad_norm": 0.16588512063026428,
      "learning_rate": 3.509036144578313e-05,
      "loss": 1.387556266784668,
      "step": 110
    },
    {
      "epoch": 0.7017543859649122,
      "grad_norm": 0.17575594782829285,
      "learning_rate": 3.358433734939759e-05,
      "loss": 1.4288148880004883,
      "step": 120
    },
    {
      "epoch": 0.7602339181286549,
      "grad_norm": 0.19012802839279175,
      "learning_rate": 3.207831325301205e-05,
      "loss": 1.3926651000976562,
      "step": 130
    },
    {
      "epoch": 0.8187134502923976,
      "grad_norm": 0.16363929212093353,
      "learning_rate": 3.057228915662651e-05,
      "loss": 1.4077316284179688,
      "step": 140
    },
    {
      "epoch": 0.8771929824561403,
      "grad_norm": 0.1760062426328659,
      "learning_rate": 2.9066265060240967e-05,
      "loss": 1.4011929512023926,
      "step": 150
    },
    {
      "epoch": 0.935672514619883,
      "grad_norm": 0.1991114318370819,
      "learning_rate": 2.756024096385542e-05,
      "loss": 1.402823543548584,
      "step": 160
    },
    {
      "epoch": 0.9941520467836257,
      "grad_norm": 0.20086798071861267,
      "learning_rate": 2.6054216867469883e-05,
      "loss": 1.3798256874084474,
      "step": 170
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.398058533668518,
      "eval_runtime": 31.3701,
      "eval_samples_per_second": 9.723,
      "eval_steps_per_second": 2.455,
      "step": 171
    },
    {
      "epoch": 1.0526315789473684,
      "grad_norm": 0.1917320042848587,
      "learning_rate": 2.454819277108434e-05,
      "loss": 1.4192428588867188,
      "step": 180
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 0.17664986848831177,
      "learning_rate": 2.3042168674698795e-05,
      "loss": 1.4044761657714844,
      "step": 190
    },
    {
      "epoch": 1.1695906432748537,
      "grad_norm": 0.18606941401958466,
      "learning_rate": 2.1536144578313255e-05,
      "loss": 1.3768987655639648,
      "step": 200
    },
    {
      "epoch": 1.2280701754385965,
      "grad_norm": 0.17365846037864685,
      "learning_rate": 2.003012048192771e-05,
      "loss": 1.3978325843811035,
      "step": 210
    },
    {
      "epoch": 1.286549707602339,
      "grad_norm": 0.18468350172042847,
      "learning_rate": 1.852409638554217e-05,
      "loss": 1.4074864387512207,
      "step": 220
    },
    {
      "epoch": 1.345029239766082,
      "grad_norm": 0.2095264494419098,
      "learning_rate": 1.7018072289156627e-05,
      "loss": 1.401200294494629,
      "step": 230
    },
    {
      "epoch": 1.4035087719298245,
      "grad_norm": 0.1631835699081421,
      "learning_rate": 1.5512048192771086e-05,
      "loss": 1.380054759979248,
      "step": 240
    },
    {
      "epoch": 1.4619883040935673,
      "grad_norm": 0.18383537232875824,
      "learning_rate": 1.4006024096385543e-05,
      "loss": 1.3649948120117188,
      "step": 250
    },
    {
      "epoch": 1.52046783625731,
      "grad_norm": 0.16412253677845,
      "learning_rate": 1.25e-05,
      "loss": 1.3921035766601562,
      "step": 260
    },
    {
      "epoch": 1.5789473684210527,
      "grad_norm": 0.16801321506500244,
      "learning_rate": 1.0993975903614459e-05,
      "loss": 1.3349422454833983,
      "step": 270
    },
    {
      "epoch": 1.6374269005847952,
      "grad_norm": 0.1807006150484085,
      "learning_rate": 9.487951807228916e-06,
      "loss": 1.4057921409606933,
      "step": 280
    },
    {
      "epoch": 1.695906432748538,
      "grad_norm": 0.17976520955562592,
      "learning_rate": 7.981927710843373e-06,
      "loss": 1.3847853660583496,
      "step": 290
    },
    {
      "epoch": 1.7543859649122808,
      "grad_norm": 0.19940093159675598,
      "learning_rate": 6.475903614457831e-06,
      "loss": 1.3632240295410156,
      "step": 300
    },
    {
      "epoch": 1.8128654970760234,
      "grad_norm": 0.18933825194835663,
      "learning_rate": 4.969879518072289e-06,
      "loss": 1.3715780258178711,
      "step": 310
    },
    {
      "epoch": 1.871345029239766,
      "grad_norm": 0.17470593750476837,
      "learning_rate": 3.463855421686747e-06,
      "loss": 1.4053767204284668,
      "step": 320
    },
    {
      "epoch": 1.9298245614035088,
      "grad_norm": 0.19853197038173676,
      "learning_rate": 1.957831325301205e-06,
      "loss": 1.425679588317871,
      "step": 330
    },
    {
      "epoch": 1.9883040935672516,
      "grad_norm": 0.17980951070785522,
      "learning_rate": 4.5180722891566265e-07,
      "loss": 1.3798848152160645,
      "step": 340
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.3889195919036865,
      "eval_runtime": 31.0554,
      "eval_samples_per_second": 9.821,
      "eval_steps_per_second": 2.479,
      "step": 342
    }
  ],
  "logging_steps": 10,
  "max_steps": 342,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.7428006154797056e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
